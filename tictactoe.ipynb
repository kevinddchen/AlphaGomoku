{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    '''Handles tic-tac-toe board.\n",
    "    \n",
    "    Variables ===========\n",
    "    \n",
    "        board: array. Representation of the board. 0=empty, 1=first player, -1=second player.\n",
    "        finished: boolean. 'True' if game is finished, 'False' otherwise.\n",
    "        winner: int. '1' if first player won, '-1' if second player won, '0' otherwise.\n",
    "        \n",
    "    Methods =============\n",
    "    \n",
    "        available_actions() -> array\n",
    "            Returns array of boolean values indicating valid moves. E.g. if all moves are valid, \n",
    "            then returns the 9-dimensional array [True, True, ..., True].\n",
    "            \n",
    "        play(move: int)\n",
    "            Play a move/action. 'move' represents the flattened dimension, i.e. move = 3*y + x.\n",
    "            Alternates between first and second players.\n",
    "            \n",
    "        find_winner() -> int\n",
    "            Computes and returns the 'winner' variable.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=np.int8)\n",
    "        self.finished = False\n",
    "        self.winner = 0\n",
    "        self._curr_player = +1\n",
    "        self._tot_moves = 0\n",
    "        \n",
    "    def available_actions(self):\n",
    "        return (self.board == 0).flatten()\n",
    "    \n",
    "    def play(self, move):\n",
    "        \n",
    "        x, y = move//3, move%3\n",
    "        \n",
    "        assert not self.finished, \"game has ended\"\n",
    "        assert self.board[x, y] == 0, \"invalid move\"\n",
    "        \n",
    "        self.board[x, y] = self._curr_player\n",
    "        self._curr_player *= -1\n",
    "        self._tot_moves += 1\n",
    "        \n",
    "        ## game ends if no more moves\n",
    "        if self._tot_moves == 9:\n",
    "            self.finished = True\n",
    "        ## game ends when there is a winner\n",
    "        self.winner = self.find_winner()\n",
    "        if self.winner != 0:\n",
    "            self.finished = True     \n",
    "        \n",
    "    def find_winner(self):\n",
    "        \n",
    "        s_col = np.sum(self.board, axis=0)\n",
    "        if 3 in s_col:    return 1\n",
    "        elif -3 in s_col: return -1\n",
    "        \n",
    "        s_row = np.sum(self.board, axis=1)\n",
    "        if 3 in s_row:    return 1\n",
    "        elif -3 in s_row: return -1\n",
    "            \n",
    "        s = self.board[0,0] + self.board[1,1] + self.board[2,2]\n",
    "        if s == 3: return 1\n",
    "        elif s == -3: return -1\n",
    "        \n",
    "        s = self.board[0,2] + self.board[1,1] + self.board[2,0]\n",
    "        if s == 3: return 1\n",
    "        elif s == -3: return -1\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "\n",
    "    \n",
    "class Player:\n",
    "    '''Player of tic-tac-toe game.\n",
    "    \n",
    "    Parameters =========\n",
    "    \n",
    "        name: string. Name of player.\n",
    "        piece: int. Either +1 for first player or -1 for second player.\n",
    "        \n",
    "    Methods ============\n",
    "    \n",
    "        play(game: TicTacToe) -> int\n",
    "            Returns move/action. 'move' represents the flattened dimension, i.e. move = 3*x + y.\n",
    "            \n",
    "        learn(episode: list)\n",
    "            Learn from episode.\n",
    "    '''\n",
    "    def __init__(self, name, piece):\n",
    "        self.name = name\n",
    "        self.piece = piece\n",
    "        \n",
    "    def play(self, game):\n",
    "        pass\n",
    "    \n",
    "    def learn(self, episode):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPlayer(Player):\n",
    "    '''Q-function learned by MC-control.\n",
    "    \n",
    "    Parameters =========\n",
    "    \n",
    "        name.\n",
    "        piece.\n",
    "        eps: float. Probability for random action.\n",
    "        discount: float. Discount factor.\n",
    "            \n",
    "    Variables ==========\n",
    "    \n",
    "        N: dict. Tracks number of state-action pairs.\n",
    "        Q: dict. Estimator of Q-function.\n",
    "    '''\n",
    "    def __init__(self, name, piece, eps=.2, discount=.96):\n",
    "        super().__init__(name, piece)\n",
    "        self.eps = eps\n",
    "        self.discount = discount\n",
    "        self.Q = {}\n",
    "        self.N = {}\n",
    "    \n",
    "    def play(self, game):\n",
    "        \n",
    "        available_actions = game.available_actions()\n",
    "        x = np.random.random()\n",
    "        \n",
    "        ## play greedy\n",
    "        if x > self.eps:\n",
    "            s = (game.board * self.piece).tobytes()\n",
    "            values = self.Q.get(s, np.zeros(9))\n",
    "            best_value = np.amax(values[available_actions])\n",
    "            actions = (values == best_value) * available_actions\n",
    "        ## play random\n",
    "        else:\n",
    "            actions = available_actions\n",
    "        \n",
    "        return np.random.choice(np.where(actions)[0])\n",
    "            \n",
    "    def learn(self, episode):\n",
    "    \n",
    "        R = episode.pop()\n",
    "        while episode:\n",
    "            a = episode.pop()\n",
    "            s = (episode.pop() * self.piece).tobytes()\n",
    "            \n",
    "            values = self.Q.get(s, np.zeros(9))\n",
    "            self.Q[s] = values\n",
    "            \n",
    "            Ns = self.N.get(s, np.zeros(9))\n",
    "            self.N[s] = Ns\n",
    "            \n",
    "            Ns[a] += 1.\n",
    "            #values[a] += self.lr * (R - values[a])\n",
    "            values[a] += (R - values[a]) / Ns[a]\n",
    "            R *= self.discount\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(p1, p2, p1_learn=False, p2_learn=False, verbose=False):\n",
    "    \n",
    "    game = TicTacToe()\n",
    "    p1_ep = []\n",
    "    p2_ep = []\n",
    "    p_i = 0\n",
    "    \n",
    "    p1.piece = +1\n",
    "    p2.piece = -1\n",
    "    \n",
    "    while not game.finished:\n",
    "        \n",
    "        ## which player's turn?\n",
    "        if p_i == 0:\n",
    "            p, ep, learn = p1, p1_ep, p1_learn\n",
    "        else:\n",
    "            p, ep, learn = p2, p2_ep, p2_learn\n",
    "\n",
    "        ## player move\n",
    "        move = p.play(game)\n",
    "        if verbose: print(\"{0:s} plays move {1:d}\".format(p.name, move))\n",
    "\n",
    "        ## update episode\n",
    "        if learn:\n",
    "            ep.append(np.copy(game.board))\n",
    "            ep.append(move)\n",
    "\n",
    "        ## update game\n",
    "        game.play(move)\n",
    "\n",
    "        p_i = (p_i+1)%2\n",
    "        \n",
    "    if verbose: print(game.board)\n",
    "    \n",
    "    ## give winner reward 1, loser reward -1\n",
    "    if game.winner == 1:\n",
    "        if verbose: print(\"winner: {0:s}.\".format(p1.name))\n",
    "        p1_ep.append(1.)\n",
    "        p2_ep.append(-1.)\n",
    "    elif game.winner == -1:\n",
    "        if verbose: print(\"winner: {0:s}.\".format(p2.name))\n",
    "        p1_ep.append(-1.)\n",
    "        p2_ep.append(1.)\n",
    "    else:\n",
    "        if verbose: print(\"tie.\")\n",
    "        p1_ep.append(0.)\n",
    "        p2_ep.append(0.)\n",
    "    \n",
    "    if p1_learn:\n",
    "        p1.learn(p1_ep)\n",
    "    if p2_learn:\n",
    "        p2.learn(p2_ep)\n",
    "        \n",
    "    return game.winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We train two agents against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = MCPlayer('agent1', 0, eps=.2)\n",
    "agent2 = MCPlayer('agent2', 0, eps=.2)\n",
    "\n",
    "for i in range(100_000):\n",
    "    play_game(agent1, agent2, p1_learn=True, p2_learn=True)\n",
    "    play_game(agent2, agent1, p1_learn=True, p2_learn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1.eps = 0\n",
    "agent2.eps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent1 plays move 4\n",
      "agent2 plays move 2\n",
      "agent1 plays move 5\n",
      "agent2 plays move 3\n",
      "agent1 plays move 0\n",
      "agent2 plays move 8\n",
      "agent1 plays move 7\n",
      "agent2 plays move 1\n",
      "agent1 plays move 6\n",
      "[[ 1 -1 -1]\n",
      " [-1  1  1]\n",
      " [ 1  1 -1]]\n",
      "tie.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_game(agent1, agent2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also play against an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = TicTacToe()\n",
    "#agent1.piece = -1 # agent goes second\n",
    "agent1.piece = +1 # agent goes first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  0, -1],\n",
       "       [ 0,  1,  0],\n",
       "       [ 1,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.play(2)\n",
    "game.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  1, -1],\n",
       "       [ 0,  1,  0],\n",
       "       [ 1,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.play(agent1.play(game))\n",
    "game.board"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
